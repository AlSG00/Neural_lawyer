{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å –≤—ã—Å—Ç—É–ø–∞–µ—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–µ–≥–æ—Å—è –Ω–∞ 152-–º —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–æ–º –∑–∞–∫–æ–Ω–µ \"–û –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\". –ï–≥–æ –∑–∞–¥–∞—á–∞ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ–±—ã –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º, –∫–∞—Å–∞—é—â–∏—Ö—Å—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –∑–∞–∫–æ–Ω–∞.\n",
    "\n",
    "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ –±–∞–∑—É –∏ –¥—Ä—É–≥–∏–µ –∑–∞–∫–æ–Ω—ã, –∏ —É–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å –¥–æ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ —é—Ä–∏—Å—Ç–∞. –í —Ä–∞–º–∫–∞—Ö –∂–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–±–æ—Ç—ã, –∞ —Ç–∞–∫–∂–µ —É—á–∏—Ç—ã–≤–∞—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π —è–∑—ã–∫ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∑–∞–∫–æ–Ω–æ–≤, –ø–æ–ø—ã—Ç–∞–µ–º—Å—è –Ω–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞—Ç—å —Ö–æ—Ç—è –±—ã —Å –æ–¥–Ω–∏–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-retrievers-bm25 openai llama-index arize-phoenix openinference-instrumentation-llama-index nemoguardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass # –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–∞—Ä–æ–ª—è–º–∏\n",
    "import os      # –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–∫—Ä—É–∂–µ–Ω–∏–µ–º –∏ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π\n",
    "\n",
    "# –ó–∞–ø—Ä–æ—Å –≤–≤–æ–¥–∞ –∫–ª—é—á–∞ –æ—Ç OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    GPTVectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    KeywordTableIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    "    ServiceContext,\n",
    "    Settings,\n",
    ")\n",
    "\n",
    "import nest_asyncio\n",
    "import phoenix as px\n",
    "\n",
    "from phoenix.evals import (\n",
    "    HallucinationEvaluator,\n",
    "    OpenAIModel,\n",
    "    QAEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    ")\n",
    "from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents\n",
    "from phoenix.trace import DocumentEvaluations, SpanEvaluations\n",
    "\n",
    "from nemoguardrails import LLMRails\n",
    "from nemoguardrails import RailsConfig\n",
    "import json\n",
    "import os\n",
    "from llama_index.core.llama_pack import download_llama_pack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–ø—Ä–æ—Å –≤–≤–æ–¥–∞ –∫–ª—é—á–∞ –æ—Ç OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "tracer_provider = TracerProvider()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
    "\n",
    "LlamaIndexInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üöÄ –û—Ç–∫—Ä–æ–π Phoenix UI –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –ø–æ —Å—Å—ã–ª–∫–µ: {session.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –≤—ã–±–æ—Ä–µ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ –ø—Ä–∏–º–µ–Ω—è–ª–∞—Å—å —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ LLM. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –±—ã–ª–æ —Ä–µ—à–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SentenceWindowRetrieverPack, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –æ—Ç–≤–µ—Ç–∞ –æ–Ω –≤—ã—è–≤–ª—è–ª –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —á–∞—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(temperature=0, model='gpt-4o')\n",
    "\n",
    "SentenceWindowRetrieverPack = download_llama_pack(\n",
    "    \"SentenceWindowRetrieverPack\", \"./sentence_window_retriever_pack\"\n",
    ")\n",
    "\n",
    "documents = SimpleDirectoryReader(input_dir=\"/content\", input_files=[\"test_uncleared.pdf\"]).load_data()\n",
    "sentence_window_retriever_pack = SentenceWindowRetrieverPack(\n",
    "    documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –∑–∞—â–∏—Ç—ã –Ω–∞ –≤—ã–±–æ—Ä –∏–º–µ–ª–∏—Å—å –ø–∞–∫–µ—Ç—ã NeMo Guardrails –∏ LlamaGuard. \n",
    "–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LlamaGuard –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å –¥–æ—Å—Ç—É–ø —É –∞–≤—Ç–æ—Ä–æ–≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è, –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞ –º–æ–º–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã, –Ω–µ –∏–º–µ–ª–æ—Å—å. \n",
    "–ü–æ—ç—Ç–æ–º—É –±—ã–ª–æ —Ä–µ—à–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Guardrails. –í –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Guardrails –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ–Ω—Ç—Ä–æ–ª—å –≤—Ö–æ–¥—è—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ—Ç–≤–µ—Ç–æ–≤ –±–æ—Ç–∞, –∞ —Ç–∞–∫ –∂–µ –≤–ø–∏—Å–∞–Ω –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. \n",
    "–ü–æ–º–∏–º–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–∞–≤–∏–ª –≤–≤–æ–¥–∞/–≤—ã–≤–æ–¥–∞, —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–º —Å–∞–π—Ç–µ Nvidia, –±—ã–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø—É–Ω–∫—Ç—ã –¥–ª—è –∑–∞–ø—Ä–µ—Ç–∞ –Ω–∞ –≤—ã–≤–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, \n",
    "–∞ —Ç–∞–∫–∂–µ –¥–æ–ø—É—â–µ–Ω—ã –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Å–ª–∞–±–ª–µ–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞ –ª–∏—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –ø–æ—Å–∫–æ–ª—å–∫—É –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∑–∞–∫–æ–Ω–∞ –æ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—å –º–æ–≥–ª–∞ –ø—É—Ç–∞—Ç—å—Å—è –∏ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ª–µ–≥–∏—Ç–∏–º–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "context = '''–ö–æ–Ω—Ç–µ–∫—Å—Ç: –¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç.\n",
    "–ü–µ—Ä–µ–¥ —Ç–æ–±–æ–π —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω —Ä–æ—Å—Å–∏–π—Å–∫–æ–π —Ñ–µ–¥–µ—Ä–∞—Ü–∏–∏ ‚Ññ152 \"–û –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\".\n",
    "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –∫–∞—Å–∞—é—â–∏–µ—Å—è –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–∫–æ–Ω–∞.\n",
    "–§–æ—Ä–º–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.\n",
    "–°–∫–∞–∂–∏, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π –≤–µ—Å—å –¥–æ—Å—Ç—É–ø–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–Ω–∏—è –æ—Ç–≤–µ—Ç–∞\\n\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_query(query, context):\n",
    "    query = context + user_query\n",
    "    response = sentence_window_retriever_pack.run(query)\n",
    "    response_processed = rails.generate(messages=[{\n",
    "        \"role\": \"context\",\n",
    "        \"content\": {\n",
    "            \"relevant_chunks\": str(response)\n",
    "        }\n",
    "    },{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": query\n",
    "    }])\n",
    "    print(\"\\nSentenseWindowRetriever:\\n\" + str(response))\n",
    "    print(\"\\nNeMo:\\n\" + response_processed[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"–ö–∞–∫–æ–π —Ä–∞–∑–º–µ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ —Ç–æ–±–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞?\"\n",
    "send_query(user_query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"–ü–µ—Ä–µ—á–∏—Å–ª–∏ –≤—Å–µ –ø—Ä–∞–≤–∞ —É–ø–æ–ª–Ω–æ–º–æ—á–µ–Ω–Ω–æ–≥–æ –æ—Ä–≥–∞–Ω–∞ –ø–æ –∑–∞—â–∏—Ç–µ –ø—Ä–∞–≤ —Å—É–±—ä–µ–∫—Ç–æ–≤ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\"\n",
    "send_query(user_query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"–ò–º–µ—é –ª–∏ —è –ø—Ä–∞–≤–æ –∑–Ω–∞—Ç—å, –∫–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ –∏–∑ –º–æ–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è?\"\n",
    "send_query(user_query, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –±—É–¥—É—â–µ–µ, —É—á–∏—Ç—ã–≤–∞—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ—É–Ω—Ü–∏–æ–Ω–∞–ª–∞ –º–æ–¥–µ–ª–∏, –æ–ø–∏—Å–∞–Ω–Ω–æ–µ –≤ –Ω–∞—á–∞–ª–µ, —Å—Ç–æ–∏–ª–æ –±—ã –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∏ –¥—Ä—É–≥–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –Ω–∏–∂–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–ª—è —Å–∂–∞—Ç–∏—è –ø—Ä–æ–º–ø—Ç–æ–º –∏ –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è. –û–Ω–∏ –ø–æ–º–æ–≥—É—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∏ –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–∑ –Ω–∏—Ö –≤–µ—Ä–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.longllmlingua import LongLLMLinguaPostprocessor  # –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "lingua = LongLLMLinguaPostprocessor(                                            # —Å–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "    instruction_str=\"Given the context, please answer the final question\",      # –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –ø—Ä–æ–º–ø—Ç –∫ –º–∏–Ω–∏-LLM\n",
    "    target_token=300,                                                           # —Å–∫–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –≤—ã—Ö–æ–¥–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å\n",
    "    rank_method=\"longllmlingua\",\n",
    "    additional_compress_kwargs={\n",
    "    \"condition_compare\": True,\n",
    "    \"condition_in_question\": \"after\",\n",
    "    \"context_budget\": \"+100\",\n",
    "    \"reorder_context\": \"sort\",  # enable document reorder\n",
    "    \"dynamic_context_compression_ratio\": 0.4, # enable dynamic compression ratio\n",
    "},                                                                            # –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    ")\n",
    "\n",
    "api_key = os.environ[\"COHERE_API_KEY\"]\n",
    "cohere_rerank = CohereRerank(api_key=api_key, top_n=2)\n",
    "\n",
    "query_engine = sentence_window_retriever_pack.as_query_engine(\n",
    "    similarity_top_k=10,    # –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã 10 —Ç–æ–ø –∑–∞–ø–∏—Å–µ–π\n",
    "    node_postprocessors=[\n",
    "        cohere_rerank,\n",
    "        lingua,             # –≤–∫–ª—é—á–∞–µ–º –º–µ—Ç–æ–¥ —Å–∂–∞—Ç–∏—è –≤ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É\n",
    "        sentence_window_retriever_pack.postprocessor\n",
    "    ],\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"–í–ø—Ä–∞–≤–µ –ª–∏ —è –∑–∞–ø—Ä–µ—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–≤–æ–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö?\", # —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
